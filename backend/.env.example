# Port configuration
PORT=3001

# AI Text Generation Configuration
# Choose one of the following providers:

# Option 1: Local Model (runs inside container - WORKS ON EC2!)
# No API key needed, runs completely offline
# AI_PROVIDER=local

# Option 2: Ollama (runs on host machine - for local development only)
# Install Ollama from https://ollama.com and run: ollama pull llama3.2
# Use host.docker.internal to access host machine from Docker
AI_PROVIDER=ollama
AI_API_URL=http://host.docker.internal:11434
OLLAMA_MODEL=llama3.2

# Option 2: OpenRouter (Cloud - FREE tier available)
# Get free API key from https://openrouter.ai/keys
# Free models: google/gemma-2-9b-it:free, meta-llama/llama-3.2-3b-instruct:free
# AI_PROVIDER=openrouter
# AI_API_KEY=your_openrouter_key_here
# OPENROUTER_MODEL=google/gemma-2-9b-it:free

# Option 3: Hugging Face (Cloud - deprecated, not recommended)
# Get free API token from https://huggingface.co/settings/tokens
# AI_PROVIDER=huggingface
# AI_API_KEY=your_huggingface_token_here
# HF_MODEL=mistralai/Mistral-7B-Instruct-v0.2

# Option 4: No configuration needed - uses faker for random text (default)
